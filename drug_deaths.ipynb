{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vince/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/vince/anaconda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2133b49d6d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/Education.xls', skiprows=range(4), usecols=['FIPS Code',\n",
    "                                                'State', 'Area name',\n",
    "                                                'Percent of adults with less than a high school diploma, 2012-2016',\n",
    "                                                'Percent of adults with a bachelor\\'s degree or higher, 2012-2016'],\n",
    "                        converters={'FIPS Code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.columns=['FIPS', 'state', 'name', '< diploma', 'degree+']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentages of people who did not get a high school diploma and who got a bachelor's degree or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['FIPS'] = data['FIPS'].apply(lambda x: x if x[2:5] != '000' else 'not county') # mark rows for US and states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data['FIPS'] != 'not county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data['FIPS'] < '57000'] # remove Puerto Rico counties, which would be outliers for several features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population = pd.read_excel('data/Population.xls', skiprows=range(2), usecols=['FIPS','Urban_Influence_Code_2013',\n",
    "                                                                              'CENSUS_2010_POP','POP_ESTIMATE_2014',\n",
    "                                                                              'INTERNATIONALMIG_2010',\n",
    "                                                                              'INTERNATIONALMIG-2011',\n",
    "                                                                              'INTERNATIONAL_MIG_2012',\n",
    "                                                                              'INTERNATIONAL_MIG_2013'],\n",
    "                           converters={'FIPS': str, 'Urban_Influence_Code_2013': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The urban influence code is not a smooth scale from 1 = most urban to 12 = least urban. It includes several categories of county — metropolitan, suburban, rural — and then ranks within each category. So it must be treted as categorical.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population.columns = ['FIPS', 'urban_inf', 'pop_2010', 'pop_2014', 'im1', 'im2', 'im3', 'im4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The urban influence code \"distinguishes metropolitan counties by population size of their metro area, and nonmetropolitan counties by size of the largest city or town and proximity to metro and micropolitan areas.\" Lower numbers are more urban. The other features being consteucted here are the change in poulation between 2010 and 2014, and the change in the international migrant population relative to the overall change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population['pop_inc'] = (population['pop_2014'] - population['pop_2010']) / population['pop_2010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population['foreign_inc'] = (population['im1'] + population['im2'] + population['im3'] + population['im4']\n",
    "                            ) / (population['pop_2014'] - population['pop_2010'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_pop = population.drop(['pop_2010', 'im1', 'im2', 'im3', 'im4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pop.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the population increase is negative, the foreign increase must be multiplied by -1 so that the division in the calculation does not turn a positive foreign increase negative and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_pop['foreign_inc'] = add_pop['foreign_inc'] * (add_pop['pop_inc'] / abs(add_pop['pop_inc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pop.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.set_index('FIPS').join(add_pop.set_index('FIPS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unemployment = pd.read_excel('data/Unemployment.xls', skiprows=range(7), usecols=['FIPStxt', 'Unemployment_rate_2014'],\n",
    "                            converters={'FIPStxt': str})\n",
    "unemployment.columns = ['FIPS', 'unemployment']\n",
    "unemployment = unemployment.set_index('FIPS')\n",
    "unemployment2 = pd.read_excel('data/CLF01.xls', sheetname='Sheet9', usecols=['STCOU', 'CLF040210D'], converters={'STCOU': str})\n",
    "unemployment2.columns = ['FIPS', 'unemployment_2009']\n",
    "unemployment = unemployment.join(unemployment2.set_index('FIPS'))\n",
    "unemployment['unemp_change'] = unemployment['unemployment_2009'] - unemployment['unemployment']\n",
    "data = data.join(unemployment.drop('unemployment_2009', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are the unemployment rate in 2014 and the change in that rate from 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poverty = pd.read_excel('data/Poverty.xls', skiprows=range(2), usecols = ['FIPStxt',\n",
    "                                                                         'PCTPOVALL_2014','MEDHHINC_2014'],\n",
    "                       converters={'FIPStxt': str})\n",
    "poverty.columns = ['FIPS', 'poverty', 'median_hh_inc'] # poverty rate and median household income\n",
    "poverty = poverty.set_index('FIPS')\n",
    "poverty2 = pd.read_excel('data/IPE01.xls', sheetname='Sheet5', usecols=['STCOU', 'IPE120209D'], converters={'STCOU': str})\n",
    "poverty2.columns = ['FIPS', 'poverty_2009']\n",
    "poverty = poverty.join(poverty2.set_index('FIPS'))\n",
    "poverty['pov_change'] = poverty['poverty_2009'] - poverty['poverty']\n",
    "data = data.join(poverty.drop('poverty_2009', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the poverty rate in 2014 and the change from 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = pd.read_excel('data/AGE01.xls', sheetname='Sheet2', usecols=['STCOU', 'AGE050210D'], converters={'STCOU': str})\n",
    "age.columns = ['FIPS', 'median_age']\n",
    "data = data.join(age.set_index('FIPS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "households1 = pd.read_excel('data/HSG02.xls', sheetname='HSG02D', usecols=['HSG200210D'])\n",
    "households2 = pd.read_excel('data/HSG02.xls', sheetname='HSG02E', usecols=['STCOU', 'HSG215210D', 'HSG220210D'],\n",
    "                          converters={'STCOU': str})\n",
    "households2.columns = ['FIPS', 'hh_afr_am', 'hh_hisp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the numbers of households headed by African-Americans and Hispanics by the total number of households to get percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "households2.loc[:, ['hh_afr_am', 'hh_hisp']] = households2[['hh_afr_am', 'hh_hisp']].div(households1['HSG200210D'], axis=0)\n",
    "data = data.join(households2.set_index('FIPS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_07 = pd.read_excel('data/HSD01.xls', sheetname='HSD01I', usecols=['HSD410209D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_female = pd.read_excel('data/HSD02.xls', sheetname='HSD02B', usecols=['STCOU', 'HSD570209D'],\n",
    "                          converters={'STCOU': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_female.columns = ['FIPS', 'hh_female']\n",
    "hh_female.loc[:, 'hh_female'] = hh_female['hh_female'] / hh_07['HSD410209D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_food_st = pd.read_excel('data/INC01.xls', sheetname='INC01J', usecols=['STCOU', 'INC454209D'],\n",
    "                          converters={'STCOU': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh_food_st.columns = ['FIPS', 'hh_food_st']\n",
    "hh_food_st.loc[:, 'hh_food_st'] = hh_food_st['hh_food_st'] / hh_07['HSD410209D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join([hh_female.set_index('FIPS'), hh_food_st.set_index('FIPS')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foreign_born = pd.read_excel('data/POP02.xls', sheetname='POP02J', usecols=['STCOU', 'POP645209D'],\n",
    "                            converters={'STCOU': str})\n",
    "foreign_born.columns = ['FIPS', 'foreign_07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_07 = pd.read_excel('data/PST01.xls', sheetname='Sheet4', usecols=['PST045207D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vets = pd.read_excel('data/VET01.xls', sheetname='VET01C', usecols=['STCOU', 'VET605209D', 'VET610209D'],\n",
    "                    converters={'STCOU': str})\n",
    "vets.columns = ['FIPS', 'vets', 'vets_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vets.loc[:, 'vets'] = vets['vets'] / pop_07['PST045207D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join([foreign_born.set_index('FIPS'), vets.set_index('FIPS')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes = pd.read_csv('data/Crime.tsv', sep='\\t', usecols=['FIPS_ST', 'FIPS_CTY', 'VIOL', 'PROPERTY'],\n",
    "                    converters={'FIPS_ST': str, 'FIPS_CTY': str, 'VIOL': float, 'PROPERTY': float}, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes.columns = ['FIPS_ST', 'FIPS_CTY', 'viol_crime', 'prop_crime']\n",
    "crimes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes['FIPS_ST'] = crimes['FIPS_ST'].apply(lambda x: '0' * (2 - len(x)) + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes['FIPS_CTY'] = crimes['FIPS_CTY'].apply(lambda x: '0' * (3 - len(x)) + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimes['FIPS'] = crimes['FIPS_ST'] + crimes['FIPS_CTY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(crimes.drop(['FIPS_ST', 'FIPS_CTY'], axis=1).set_index('FIPS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[:, ['viol_crime', 'prop_crime']] = data[['viol_crime', 'prop_crime']].div(data['pop_2014'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the missing values occur in records missing multiple values, and dropping all of them would only reduce the number of records from 3,152 to 3,130, so drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is reasonable that these values could be zero, so proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the stats, the dataset certainly contains strong outliers that will need to be dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deaths = pd.read_csv('data/Drug_deaths.csv', usecols=['FIPS', 'Year', 'Estimated Age-adjusted Death Rate, 16 Categories (in ranges)'],\n",
    "                    converters={'FIPS': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = deaths[deaths['Year'] == 2014]\n",
    "targets = targets.drop('Year', axis=1)\n",
    "targets.columns = ['FIPS', 'death_rate']\n",
    "targets.loc[:, 'FIPS'] = targets['FIPS'].apply(lambda x: '0' + x if len(x) == 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_num(string):\n",
    "    match = re.search('\\d+', string)\n",
    "    return int(match.group()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets['numeric'] = targets['death_rate'].apply(lambda x: get_num(x) if x != '<2' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.join(targets.set_index('FIPS')) # drop na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['death_rate'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four counties had boundaries redrawn after 2000, and do not appear in the opioid deaths dataset, so they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['08001', '08014', '08059', '08123'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['numeric'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value of 31 fits the standard definition of an outlier as less than Q1 - 1.5\\*IQR or greater than Q3 + 1.5\\*IQR. Here that applies only to values >29. Where are these outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_outliers = targets[targets['numeric'] == 31]['FIPS']\n",
    "target_outliers = data.loc[target_outliers, ['state', 'name']]\n",
    "print(len(target_outliers))\n",
    "target_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These outliers appear to be concentrated in some states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_by_state = pd.DataFrame(target_outliers.groupby('state').size(), columns=['outliers'])\n",
    "counties_by_state = pd.DataFrame(data.groupby('state').size(), columns = ['total'])\n",
    "outliers_by_state['total'] = counties_by_state['total']\n",
    "outliers_by_state['percent'] = 100 * outliers_by_state['outliers']/outliers_by_state['total']\n",
    "outliers_by_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at overall distribution of targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(data.groupby(['state', 'numeric']).size())\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = counts.reset_index()\n",
    "counts.columns = ['state', 'numeric', 'count']\n",
    "counts['total'] = counts.apply(lambda row: counties_by_state.loc[row['state'], 'total'], axis=1)\n",
    "counts['percent'] = counts['count'] / counts['total']\n",
    "states = sorted(counts['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [16.0, 8.0]\n",
    "ax = sns.stripplot(data=counts, x='state', y='numeric', hue='percent', palette='OrRd')\n",
    "ax.legend_.remove()\n",
    "ax.set_title('Clustering counties by death rate and state (darker = higher percentage)', size=18)\n",
    "ax.set_ylabel('death rate')\n",
    "ax.figure.savefig('images/county_rates.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there are some states with outlying concentrations of counties with low or high death rates, the distribution is fairly even overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [8.0, 4.0]\n",
    "target_hist = sns.distplot(targets['numeric'], bins=16, fit=norm, kde=False)\n",
    "target_hist.figure.savefig('images/target_hist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target distribution is a little skewed but follows a roughly normal curve except for the spike at the highest value. Experimentation found that classification works better with these target outliers included, but the outliers in the predictors need to be dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw = data.copy()\n",
    "data = data.drop(['state', 'name', 'pop_2014'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate = data.drop(['urban_inf', 'death_rate'], axis=1).corr().abs()\n",
    "print(bivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**poverty** correlates strongly with several other variables, so drop it. The two crime variables correlate strongly with each other, so combine them into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['crime'] = (data['viol_crime'] + data['prop_crime'])\n",
    "data = data.drop(['viol_crime', 'prop_crime', 'poverty'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = data.drop(['urban_inf', 'death_rate'], axis=1).corr().abs()\n",
    "heatmap = sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "heatmap.figure.savefig('images/heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other correlations, but variance inflation factor (VIF) analysis will be used to determine which should be removed. But first look at outliers in the independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_outliers(df, multiplier=1.5):\n",
    "    stats = df.describe()\n",
    "    iqr = stats.loc['75%'] - stats.loc['25%']\n",
    "    lower = stats.loc['25%'] - multiplier * iqr\n",
    "    upper = stats.loc['75%'] + multiplier * iqr\n",
    "    return ((df < lower) | (df > upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = get_outliers(data.drop(['urban_inf', 'death_rate', 'numeric'], axis=1))\n",
    "len(data[outliers.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreme_outliers = get_outliers(data.drop(['urban_inf', 'death_rate', 'numeric'], axis=1), 2.5)\n",
    "len(data[extreme_outliers.any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_outliers = list((data[extreme_outliers.sum(axis=1) > 1]).index)\n",
    "len(xx_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost half the dataset contains outliers, and more than a quarter contains extreme outliers that are more than 2.5 times the IQR below the first quartile or above the third. As an alternative to dropping a large number of samples, apply robust scaling to the predictors. Scikit-learn has two solutions, robust scaling and quantile transformation. Try them both. If necessary drop the most extreme (xx) outliers, those samples having more than one extreme outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Having gone through the same iterative process as the notebook on the master branch and not achieving significantly better results, the data will be split from the outset to produce balanced train/test sets with respect to high/low death rates, with high being 15 or greater, and low being 13 or less. This will have the desired effect only for the last, binary, classification attempt, as the intermediary classifications into 16, 8 and 4 classes will no longer be stratified according to the progressive grouping scheme.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data['high_death_rate'] = np.where(data['numeric'] < 15, 0, 1)\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(data.drop('death_rate', axis=1),\n",
    "                                                                     data['death_rate'], test_size=.2,\n",
    "                                                                     stratify=data['high_death_rate'], random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to separate the training and test data before scaling/transforming to prevent data leakage from the test data when fitting the scaling and transformation algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer\n",
    "robust = RobustScaler()\n",
    "quantile = QuantileTransformer()\n",
    "\n",
    "r_train = pd.DataFrame(robust.fit_transform(data_train.drop(['urban_inf'], axis=1)),\n",
    "                       index=data_train.index, columns=data_train.drop(['urban_inf'], axis=1).columns)\n",
    "r_train['urban_inf'] = data_train['urban_inf']\n",
    "\n",
    "q_train = pd.DataFrame(quantile.fit_transform(data_train.drop(['urban_inf'], axis=1)),\n",
    "                       index=data_train.index, columns=data_train.drop(['urban_inf'], axis=1).columns)\n",
    "q_train['urban_inf'] = data_train['urban_inf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Both robust scaling and quantile transformation leave binary features unchanged, so __urban_inf__ will be one-hot encoded later.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use VIF analysis to programmatically eliminate the variables with the highest VIF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.549152</td>\n",
       "      <td>&lt; diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.380767</td>\n",
       "      <td>degree+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.675102</td>\n",
       "      <td>pop_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.008448</td>\n",
       "      <td>foreign_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.924162</td>\n",
       "      <td>unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.080467</td>\n",
       "      <td>unemp_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.008699</td>\n",
       "      <td>median_hh_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.142916</td>\n",
       "      <td>pov_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.306545</td>\n",
       "      <td>median_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.715394</td>\n",
       "      <td>hh_afr_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.377824</td>\n",
       "      <td>hh_hisp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.905629</td>\n",
       "      <td>hh_female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.366569</td>\n",
       "      <td>hh_food_st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.907921</td>\n",
       "      <td>foreign_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.091195</td>\n",
       "      <td>vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.375355</td>\n",
       "      <td>vets_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.392641</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VIF       features\n",
       "0   4.549152      < diploma\n",
       "1   3.380767        degree+\n",
       "2   1.675102        pop_inc\n",
       "3   1.008448    foreign_inc\n",
       "4   1.924162   unemployment\n",
       "5   1.080467   unemp_change\n",
       "6   3.008699  median_hh_inc\n",
       "7   1.142916     pov_change\n",
       "8   2.306545     median_age\n",
       "9   2.715394      hh_afr_am\n",
       "10  2.377824        hh_hisp\n",
       "11  3.905629      hh_female\n",
       "12  3.366569     hh_food_st\n",
       "13  2.907921     foreign_07\n",
       "14  2.091195           vets\n",
       "15  1.375355      vets_male\n",
       "16  1.392641          crime"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "remove = ['urban_inf', 'numeric']\n",
    "features = r_train.drop(remove, axis=1)\n",
    "vif[\"VIF\"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
    "vif[\"features\"] = features.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.452512</td>\n",
       "      <td>degree+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.410385</td>\n",
       "      <td>pop_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.006773</td>\n",
       "      <td>foreign_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.458214</td>\n",
       "      <td>unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.064378</td>\n",
       "      <td>unemp_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.091204</td>\n",
       "      <td>pov_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.468414</td>\n",
       "      <td>hh_afr_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.122044</td>\n",
       "      <td>hh_hisp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.163958</td>\n",
       "      <td>vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.227601</td>\n",
       "      <td>vets_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.266945</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VIF      features\n",
       "0   1.452512       degree+\n",
       "1   1.410385       pop_inc\n",
       "2   1.006773   foreign_inc\n",
       "3   1.458214  unemployment\n",
       "4   1.064378  unemp_change\n",
       "5   1.091204    pov_change\n",
       "6   1.468414     hh_afr_am\n",
       "7   1.122044       hh_hisp\n",
       "8   1.163958          vets\n",
       "9   1.227601     vets_male\n",
       "10  1.266945         crime"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_VIF = max(vif['VIF'])\n",
    "while max_VIF > 2:\n",
    "    remove = remove + list(vif[vif['VIF'] == max_VIF]['features'])\n",
    "    features = r_train.drop(remove, axis=1)\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
    "    vif[\"features\"] = features.columns\n",
    "    max_VIF = max(vif['VIF'])\n",
    "    \n",
    "r_features = list(features.columns) + ['urban_inf']\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.839509</td>\n",
       "      <td>&lt; diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.055705</td>\n",
       "      <td>degree+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.332232</td>\n",
       "      <td>pop_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.485744</td>\n",
       "      <td>foreign_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.442237</td>\n",
       "      <td>unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.526456</td>\n",
       "      <td>unemp_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.848987</td>\n",
       "      <td>median_hh_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.355851</td>\n",
       "      <td>pov_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.631193</td>\n",
       "      <td>median_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.378383</td>\n",
       "      <td>hh_afr_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.815452</td>\n",
       "      <td>hh_hisp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.521652</td>\n",
       "      <td>hh_female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.249074</td>\n",
       "      <td>hh_food_st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.696382</td>\n",
       "      <td>foreign_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.330329</td>\n",
       "      <td>vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.712523</td>\n",
       "      <td>vets_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.499154</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VIF       features\n",
       "0   13.839509      < diploma\n",
       "1   12.055705        degree+\n",
       "2    7.332232        pop_inc\n",
       "3    5.485744    foreign_inc\n",
       "4    8.442237   unemployment\n",
       "5    4.526456   unemp_change\n",
       "6    9.848987  median_hh_inc\n",
       "7    4.355851     pov_change\n",
       "8    9.631193     median_age\n",
       "9    9.378383      hh_afr_am\n",
       "10  13.815452        hh_hisp\n",
       "11  13.521652      hh_female\n",
       "12  13.249074     hh_food_st\n",
       "13  15.696382     foreign_07\n",
       "14   7.330329           vets\n",
       "15   4.712523      vets_male\n",
       "16   6.499154          crime"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif2 = pd.DataFrame()\n",
    "remove = ['urban_inf', 'numeric']\n",
    "features2 = q_train.drop(remove, axis=1)\n",
    "vif2[\"VIF\"] = [variance_inflation_factor(features2.values, i) for i in range(features2.shape[1])]\n",
    "vif2[\"features\"] = features2.columns\n",
    "vif2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.095568</td>\n",
       "      <td>degree+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.917317</td>\n",
       "      <td>pop_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.129618</td>\n",
       "      <td>foreign_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.527086</td>\n",
       "      <td>unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.304151</td>\n",
       "      <td>unemp_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.523071</td>\n",
       "      <td>pov_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.104386</td>\n",
       "      <td>hh_afr_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.551572</td>\n",
       "      <td>hh_hisp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.842143</td>\n",
       "      <td>vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.514568</td>\n",
       "      <td>vets_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.938132</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VIF      features\n",
       "0   6.095568       degree+\n",
       "1   5.917317       pop_inc\n",
       "2   5.129618   foreign_inc\n",
       "3   5.527086  unemployment\n",
       "4   4.304151  unemp_change\n",
       "5   3.523071    pov_change\n",
       "6   6.104386     hh_afr_am\n",
       "7   5.551572       hh_hisp\n",
       "8   3.842143          vets\n",
       "9   3.514568     vets_male\n",
       "10  5.938132         crime"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_VIF = max(vif2['VIF'])\n",
    "while len(vif2) > 11:\n",
    "    remove = remove + list(vif2[vif2['VIF'] == max_VIF]['features'])\n",
    "    features2 = q_train.drop(remove, axis=1)\n",
    "    vif2 = pd.DataFrame()\n",
    "    vif2[\"VIF\"] = [variance_inflation_factor(features2.values, i) for i in range(features2.shape[1])]\n",
    "    vif2[\"features\"] = features2.columns\n",
    "    max_VIF = max(vif2['VIF'])\n",
    "\n",
    "q_features = list(features2.columns) + ['urban_inf']   \n",
    "vif2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the VIF scores were higher with the quantile-transformed data, the order was the same, so proceed with the 11 features from the scaled data that scored below 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a range of classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xr1_train = r_train.loc[:, r_features]\n",
    "Xr1_train = pd.get_dummies(Xr1_train, prefix='urb_inf_', columns=['urban_inf'])\n",
    "Yr1_train = targets_train\n",
    "\n",
    "Xq1_train = q_train.loc[:, r_features]\n",
    "Xq1_train = pd.get_dummies(Xq1_train, prefix='urb_inf_', columns=['urban_inf'])\n",
    "Yq1_train = targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "matthews = make_scorer(matthews_corrcoef)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "lrc = LogisticRegression(class_weight='balanced')\n",
    "gbc = GradientBoostingClassifier()\n",
    "sgd = SGDClassifier(class_weight='balanced', tol=1e-3)\n",
    "rfc = RandomForestClassifier(class_weight='balanced')\n",
    "svc = SVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [lrc, gbc, sgd, rfc, svc, knn]\n",
    "names = ['lrc', 'gbc', 'sgd', 'rfc', 'svc', 'knn']\n",
    "full_names = {'lrc':'Logistic regression', 'gbc':'Gradient boosting', 'sgd':'Stochastic gradient descent',\n",
    "              'rfc':'Random forest', 'svc':'Support vector', 'knn':'K-Nearest neighbors'}\n",
    "\n",
    "index = pd.MultiIndex.from_product([['Y16', 'Y8', 'Y4', 'Y2'], ['r', 'q'], [1, 2]])\n",
    "results = pd.DataFrame(index=index, columns=names)\n",
    "\n",
    "def run_trials(X, Y, targets, scale, feature_set):\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        scores = cross_val_score(clf, X, Y, cv=5, scoring=matthews)\n",
    "        results.loc[targets, scale, feature_set][name] = np.mean(scores)\n",
    "        %time print('{} scores: {}'.format(full_names[name], scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.05086417  0.07282134  0.06603775  0.04443182  0.05898859]\n",
      "CPU times: user 1.75 ms, sys: 106 µs, total: 1.86 ms\n",
      "Wall time: 464 µs\n",
      "Gradient boosting scores: [ 0.04641526  0.07536195  0.06416592  0.06177084  0.09184377]\n",
      "CPU times: user 440 µs, sys: 54 µs, total: 494 µs\n",
      "Wall time: 477 µs\n",
      "Stochastic gradient descent scores: [ 0.0344151   0.02383705  0.04745438  0.05397181  0.02920583]\n",
      "CPU times: user 1.56 ms, sys: 73 µs, total: 1.63 ms\n",
      "Wall time: 407 µs\n",
      "Random forest scores: [ 0.03741979  0.01701082  0.06501173  0.02598711  0.07604956]\n",
      "CPU times: user 375 µs, sys: 48 µs, total: 423 µs\n",
      "Wall time: 407 µs\n",
      "Support vector scores: [ 0.07783805  0.09284539  0.0659536   0.07159398  0.09485769]\n",
      "CPU times: user 404 µs, sys: 50 µs, total: 454 µs\n",
      "Wall time: 440 µs\n",
      "K-Nearest neighbors scores: [ 0.07062363  0.01861974  0.07746329  0.03420713  0.06930431]\n",
      "CPU times: user 380 µs, sys: 32 µs, total: 412 µs\n",
      "Wall time: 417 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr1_train, Yr1_train, 'Y16', 'r', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the stock classifiers performed poorly, with support vector doing the best, followed by gradient boosting and logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.05249489  0.06837129  0.04810064  0.05307293  0.06903587]\n",
      "CPU times: user 2.63 ms, sys: 220 µs, total: 2.85 ms\n",
      "Wall time: 721 µs\n",
      "Gradient boosting scores: [ 0.06354822  0.06196945  0.06606989  0.06196256  0.09073018]\n",
      "CPU times: user 369 µs, sys: 48 µs, total: 417 µs\n",
      "Wall time: 405 µs\n",
      "Stochastic gradient descent scores: [ 0.0382684   0.03000142  0.03315811  0.04686783  0.0570851 ]\n",
      "CPU times: user 2 ms, sys: 169 µs, total: 2.17 ms\n",
      "Wall time: 537 µs\n",
      "Random forest scores: [ 0.03685459  0.05119224  0.0439854   0.01998485  0.07507335]\n",
      "CPU times: user 397 µs, sys: 48 µs, total: 445 µs\n",
      "Wall time: 432 µs\n",
      "Support vector scores: [ 0.02685441  0.05997005  0.053471    0.04396285  0.05533475]\n",
      "CPU times: user 428 µs, sys: 54 µs, total: 482 µs\n",
      "Wall time: 469 µs\n",
      "K-Nearest neighbors scores: [ 0.01657498  0.03476783  0.02542581  0.03843304  0.0462092 ]\n",
      "CPU times: user 360 µs, sys: 43 µs, total: 403 µs\n",
      "Wall time: 395 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq1_train, Yq1_train, 'Y16', 'q', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantile-transformed data performed even worse. Try an alternative selection process starting with correlations with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< diploma        0.137277\n",
       "degree+          0.135954\n",
       "pop_inc          0.066918\n",
       "foreign_inc      0.004850\n",
       "unemployment     0.315348\n",
       "unemp_change     0.183969\n",
       "median_hh_inc    0.241291\n",
       "pov_change       0.097023\n",
       "median_age       0.083324\n",
       "hh_afr_am        0.141008\n",
       "hh_hisp          0.044675\n",
       "hh_female        0.071277\n",
       "hh_food_st       0.247499\n",
       "foreign_07       0.083056\n",
       "vets             0.143301\n",
       "vets_male        0.037117\n",
       "crime            0.143831\n",
       "Name: numeric, dtype: float64"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bivariate = r_train.drop('urban_inf', axis=1).corr().abs()\n",
    "bivariate.loc['numeric'].drop('numeric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features2 = list(bivariate[bivariate.loc['numeric'] > .05].drop('numeric').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.091634</td>\n",
       "      <td>&lt; diploma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.349758</td>\n",
       "      <td>degree+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.673822</td>\n",
       "      <td>pop_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.887261</td>\n",
       "      <td>unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.077989</td>\n",
       "      <td>unemp_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.997277</td>\n",
       "      <td>median_hh_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.126923</td>\n",
       "      <td>pov_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.109809</td>\n",
       "      <td>median_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.551090</td>\n",
       "      <td>hh_afr_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.868226</td>\n",
       "      <td>hh_female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.350698</td>\n",
       "      <td>hh_food_st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.219591</td>\n",
       "      <td>foreign_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.797111</td>\n",
       "      <td>vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.384731</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VIF       features\n",
       "0   4.091634      < diploma\n",
       "1   3.349758        degree+\n",
       "2   1.673822        pop_inc\n",
       "3   1.887261   unemployment\n",
       "4   1.077989   unemp_change\n",
       "5   2.997277  median_hh_inc\n",
       "6   1.126923     pov_change\n",
       "7   2.109809     median_age\n",
       "8   2.551090      hh_afr_am\n",
       "9   3.868226      hh_female\n",
       "10  3.350698     hh_food_st\n",
       "11  2.219591     foreign_07\n",
       "12  1.797111           vets\n",
       "13  1.384731          crime"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "features = r_train.loc[:, features2]\n",
    "vif[\"VIF\"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
    "vif[\"features\"] = features.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.546230</td>\n",
       "      <td>degree+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.549868</td>\n",
       "      <td>pop_inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.465020</td>\n",
       "      <td>unemployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.070656</td>\n",
       "      <td>unemp_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.097285</td>\n",
       "      <td>pov_change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.943621</td>\n",
       "      <td>median_age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.388109</td>\n",
       "      <td>hh_afr_am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.344904</td>\n",
       "      <td>foreign_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.646127</td>\n",
       "      <td>vets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.318872</td>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VIF      features\n",
       "0  1.546230       degree+\n",
       "1  1.549868       pop_inc\n",
       "2  1.465020  unemployment\n",
       "3  1.070656  unemp_change\n",
       "4  1.097285    pov_change\n",
       "5  1.943621    median_age\n",
       "6  1.388109     hh_afr_am\n",
       "7  1.344904    foreign_07\n",
       "8  1.646127          vets\n",
       "9  1.318872         crime"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_VIF = max(vif['VIF'])\n",
    "while max_VIF > 2:\n",
    "    remove = list(vif[vif['VIF'] == max_VIF]['features'])\n",
    "    reduced = [feature for feature in features if feature not in remove]\n",
    "    features = r_train.loc[:, reduced]\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(features.values, i) for i in range(features.shape[1])]\n",
    "    vif[\"features\"] = features.columns\n",
    "    max_VIF = max(vif['VIF'])\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features2 = list(vif['features']) + ['urban_inf']\n",
    "Xr2_train = r_train.loc[:, features2]\n",
    "Xr2_train = pd.get_dummies(Xr2_train, prefix='urb_inf_', columns=['urban_inf'])\n",
    "Yr2_train = targets_train\n",
    "\n",
    "Xq2_train = q_train.loc[:, (features2)]\n",
    "Xq2_train = pd.get_dummies(Xq2_train, prefix='urb_inf_', columns=['urban_inf'])\n",
    "Yq2_train = targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.06412226  0.07609716  0.0511766   0.05193429  0.07408108]\n",
      "CPU times: user 1.75 ms, sys: 83 µs, total: 1.84 ms\n",
      "Wall time: 459 µs\n",
      "Gradient boosting scores: [ 0.06294905  0.05162787  0.08661119  0.05421571  0.09498584]\n",
      "CPU times: user 490 µs, sys: 65 µs, total: 555 µs\n",
      "Wall time: 537 µs\n",
      "Stochastic gradient descent scores: [ 0.03385248  0.03746709  0.06650019  0.04284771  0.06014903]\n",
      "CPU times: user 5.65 ms, sys: 917 µs, total: 6.57 ms\n",
      "Wall time: 1.81 ms\n",
      "Random forest scores: [ 0.05550658  0.07157721  0.06044891  0.05236204  0.10527893]\n",
      "CPU times: user 1.05 ms, sys: 128 µs, total: 1.17 ms\n",
      "Wall time: 1.16 ms\n",
      "Support vector scores: [ 0.07190563  0.07200346  0.09713951  0.09069434  0.10320002]\n",
      "CPU times: user 384 µs, sys: 45 µs, total: 429 µs\n",
      "Wall time: 422 µs\n",
      "K-Nearest neighbors scores: [ 0.04406258  0.06012846  0.07290166  0.03992521  0.05960594]\n",
      "CPU times: user 537 µs, sys: 113 µs, total: 650 µs\n",
      "Wall time: 602 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr2_train, Yr2_train, 'Y16', 'r', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.05536076  0.0661584   0.04062156  0.05498016  0.08575282]\n",
      "CPU times: user 1.61 ms, sys: 78 µs, total: 1.69 ms\n",
      "Wall time: 421 µs\n",
      "Gradient boosting scores: [ 0.02999205  0.0409069   0.09083293  0.05190793  0.08727649]\n",
      "CPU times: user 409 µs, sys: 52 µs, total: 461 µs\n",
      "Wall time: 451 µs\n",
      "Stochastic gradient descent scores: [ 0.01562488  0.03972564  0.05758096  0.05178885  0.03603954]\n",
      "CPU times: user 1.98 ms, sys: 137 µs, total: 2.12 ms\n",
      "Wall time: 524 µs\n",
      "Random forest scores: [ 0.05373383  0.08453299  0.03799896  0.05498294  0.05301281]\n",
      "CPU times: user 423 µs, sys: 77 µs, total: 500 µs\n",
      "Wall time: 466 µs\n",
      "Support vector scores: [ 0.03790855  0.06135298  0.04949953  0.04833966  0.06779856]\n",
      "CPU times: user 414 µs, sys: 53 µs, total: 467 µs\n",
      "Wall time: 457 µs\n",
      "K-Nearest neighbors scores: [ 0.05933857  0.04082642  0.05666089  0.01630364  0.029316  ]\n",
      "CPU times: user 390 µs, sys: 49 µs, total: 439 µs\n",
      "Wall time: 433 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq2_train, Yq2_train, 'Y16', 'q', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are very close for both training sets, but also very poor. Try combining targets to make fewer classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_targets(input):\n",
    "    targets = sorted(input.unique(), key=lambda x: int(re.search('\\d+(?=-)', x).group()))\n",
    "    first = []\n",
    "    second = []\n",
    "    for i, r in enumerate(targets):\n",
    "        first.append(r) if i % 2 == 0 else second.append(r)\n",
    "    if len(first) != len(second):\n",
    "        second.append('30-31.9')\n",
    "    conversions = {}\n",
    "    for start, end in zip(first, second):\n",
    "        new_value = re.search('\\d+-', start).group() + re.search('(?<=-)\\d+.\\d+', end).group()\n",
    "        conversions.update(dict.fromkeys([start, end], new_value))\n",
    "    return input.apply(lambda x: conversions[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_16_train = targets_train.apply(lambda x: '0-1.9' if x == '<2' else x)\n",
    "Y_16_train = Y_16_train.apply(lambda x: '30-31.9' if x == '30+' else x)\n",
    "\n",
    "Y_8_train = combine_targets(Y_16_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.1321164   0.12608619  0.11768745  0.16575065  0.1230672 ]\n",
      "CPU times: user 1.58 ms, sys: 82 µs, total: 1.66 ms\n",
      "Wall time: 416 µs\n",
      "Gradient boosting scores: [ 0.15625616  0.11245976  0.09628238  0.12214904  0.14966475]\n",
      "CPU times: user 396 µs, sys: 49 µs, total: 445 µs\n",
      "Wall time: 434 µs\n",
      "Stochastic gradient descent scores: [ 0.07146414  0.06225771  0.03675962  0.06354764  0.0873632 ]\n",
      "CPU times: user 1.63 ms, sys: 71 µs, total: 1.7 ms\n",
      "Wall time: 425 µs\n",
      "Random forest scores: [ 0.12293009  0.11344306  0.11428825  0.12119113  0.12829457]\n",
      "CPU times: user 368 µs, sys: 54 µs, total: 422 µs\n",
      "Wall time: 404 µs\n",
      "Support vector scores: [ 0.16176329  0.1552665   0.12118051  0.14181695  0.18066868]\n",
      "CPU times: user 381 µs, sys: 51 µs, total: 432 µs\n",
      "Wall time: 419 µs\n",
      "K-Nearest neighbors scores: [ 0.15527279  0.11922847  0.1264419   0.05341478  0.10179591]\n",
      "CPU times: user 358 µs, sys: 40 µs, total: 398 µs\n",
      "Wall time: 390 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr1_train, Y_8_train, 'Y8', 'r', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.12944753  0.09861998  0.11943153  0.15875462  0.12862111]\n",
      "CPU times: user 2.13 ms, sys: 203 µs, total: 2.33 ms\n",
      "Wall time: 589 µs\n",
      "Gradient boosting scores: [ 0.15661915  0.11279916  0.13877335  0.14226679  0.17363891]\n",
      "CPU times: user 407 µs, sys: 50 µs, total: 457 µs\n",
      "Wall time: 446 µs\n",
      "Stochastic gradient descent scores: [ 0.08349209  0.07375127  0.09280278  0.0832209   0.13114542]\n",
      "CPU times: user 2.25 ms, sys: 115 µs, total: 2.36 ms\n",
      "Wall time: 595 µs\n",
      "Random forest scores: [ 0.12133344  0.1323677   0.07397829  0.11168883  0.14000666]\n",
      "CPU times: user 415 µs, sys: 48 µs, total: 463 µs\n",
      "Wall time: 450 µs\n",
      "Support vector scores: [ 0.17969014  0.14638884  0.15362061  0.17601458  0.14875717]\n",
      "CPU times: user 474 µs, sys: 64 µs, total: 538 µs\n",
      "Wall time: 520 µs\n",
      "K-Nearest neighbors scores: [ 0.13861981  0.1179019   0.10333352  0.09355657  0.12178725]\n",
      "CPU times: user 409 µs, sys: 62 µs, total: 471 µs\n",
      "Wall time: 459 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr2_train, Y_8_train, 'Y8', 'r', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.10162229  0.10126853  0.11825375  0.15335409  0.1460493 ]\n",
      "CPU times: user 1.67 ms, sys: 84 µs, total: 1.75 ms\n",
      "Wall time: 435 µs\n",
      "Gradient boosting scores: [ 0.13463337  0.14436889  0.12276287  0.15094769  0.14406414]\n",
      "CPU times: user 386 µs, sys: 44 µs, total: 430 µs\n",
      "Wall time: 418 µs\n",
      "Stochastic gradient descent scores: [ 0.10419837  0.06386417  0.08789412  0.06599048  0.10857556]\n",
      "CPU times: user 1.55 ms, sys: 79 µs, total: 1.63 ms\n",
      "Wall time: 408 µs\n",
      "Random forest scores: [ 0.13213705  0.07174946  0.1080819   0.08751764  0.13621233]\n",
      "CPU times: user 383 µs, sys: 50 µs, total: 433 µs\n",
      "Wall time: 418 µs\n",
      "Support vector scores: [ 0.11399134  0.11040416  0.10278132  0.14003048  0.10866748]\n",
      "CPU times: user 389 µs, sys: 52 µs, total: 441 µs\n",
      "Wall time: 429 µs\n",
      "K-Nearest neighbors scores: [ 0.09498106  0.09107381  0.09035221  0.15025924  0.06981338]\n",
      "CPU times: user 478 µs, sys: 66 µs, total: 544 µs\n",
      "Wall time: 523 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq1_train, Y_8_train, 'Y8', 'q', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.12785724  0.11110969  0.123671    0.14998998  0.15340912]\n",
      "CPU times: user 2.01 ms, sys: 132 µs, total: 2.14 ms\n",
      "Wall time: 526 µs\n",
      "Gradient boosting scores: [ 0.12680603  0.13410442  0.10383225  0.12777934  0.16901651]\n",
      "CPU times: user 370 µs, sys: 47 µs, total: 417 µs\n",
      "Wall time: 402 µs\n",
      "Stochastic gradient descent scores: [ 0.08006019  0.09152391  0.07221708  0.08152844  0.09595232]\n",
      "CPU times: user 2.24 ms, sys: 125 µs, total: 2.37 ms\n",
      "Wall time: 583 µs\n",
      "Random forest scores: [ 0.15639983  0.1120778   0.06329557  0.14433139  0.12254405]\n",
      "CPU times: user 403 µs, sys: 48 µs, total: 451 µs\n",
      "Wall time: 444 µs\n",
      "Support vector scores: [ 0.10983792  0.10707372  0.08299396  0.14146136  0.12116338]\n",
      "CPU times: user 372 µs, sys: 50 µs, total: 422 µs\n",
      "Wall time: 404 µs\n",
      "K-Nearest neighbors scores: [ 0.09086141  0.12156315  0.12144978  0.12652622  0.10239106]\n",
      "CPU times: user 383 µs, sys: 36 µs, total: 419 µs\n",
      "Wall time: 413 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq2_train, Y_8_train, 'Y8', 'q', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was significant improvement, but performance is still poor. Try reducing to 4 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_4_train = combine_targets(Y_8_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.24111678  0.29677785  0.2335296   0.24637144  0.25710789]\n",
      "CPU times: user 1.87 ms, sys: 135 µs, total: 2.01 ms\n",
      "Wall time: 500 µs\n",
      "Gradient boosting scores: [ 0.28371812  0.22359973  0.24676684  0.30355216  0.24540668]\n",
      "CPU times: user 572 µs, sys: 126 µs, total: 698 µs\n",
      "Wall time: 633 µs\n",
      "Stochastic gradient descent scores: [ 0.08826504  0.18323008  0.13911     0.16819022  0.09971837]\n",
      "CPU times: user 1.93 ms, sys: 301 µs, total: 2.23 ms\n",
      "Wall time: 764 µs\n",
      "Random forest scores: [ 0.22923467  0.2052008   0.21288875  0.15193052  0.20464668]\n",
      "CPU times: user 399 µs, sys: 49 µs, total: 448 µs\n",
      "Wall time: 437 µs\n",
      "Support vector scores: [ 0.25490224  0.29562512  0.27366052  0.28031115  0.28125678]\n",
      "CPU times: user 563 µs, sys: 72 µs, total: 635 µs\n",
      "Wall time: 618 µs\n",
      "K-Nearest neighbors scores: [ 0.22669223  0.26371651  0.17223466  0.1753743   0.20189916]\n",
      "CPU times: user 386 µs, sys: 31 µs, total: 417 µs\n",
      "Wall time: 424 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr1_train, Y_4_train, 'Y4', 'r', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.20733347  0.26372434  0.21958306  0.24569324  0.27005468]\n",
      "CPU times: user 2.81 ms, sys: 222 µs, total: 3.03 ms\n",
      "Wall time: 756 µs\n",
      "Gradient boosting scores: [ 0.31154593  0.25577977  0.24800647  0.29730169  0.29253908]\n",
      "CPU times: user 397 µs, sys: 48 µs, total: 445 µs\n",
      "Wall time: 433 µs\n",
      "Stochastic gradient descent scores: [ 0.09927232  0.1254128   0.19847473  0.18435574  0.13184086]\n",
      "CPU times: user 1.63 ms, sys: 81 µs, total: 1.71 ms\n",
      "Wall time: 429 µs\n",
      "Random forest scores: [ 0.19934942  0.20364685  0.20628974  0.21866901  0.22646789]\n",
      "CPU times: user 374 µs, sys: 49 µs, total: 423 µs\n",
      "Wall time: 408 µs\n",
      "Support vector scores: [ 0.27116062  0.28695198  0.31797694  0.33580963  0.25736527]\n",
      "CPU times: user 413 µs, sys: 46 µs, total: 459 µs\n",
      "Wall time: 446 µs\n",
      "K-Nearest neighbors scores: [ 0.2239976   0.25488042  0.21285002  0.23744324  0.23771442]\n",
      "CPU times: user 364 µs, sys: 26 µs, total: 390 µs\n",
      "Wall time: 395 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr2_train, Y_4_train, 'Y4', 'r', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.22116479  0.23299329  0.21087918  0.23937598  0.2780047 ]\n",
      "CPU times: user 1.66 ms, sys: 121 µs, total: 1.78 ms\n",
      "Wall time: 445 µs\n",
      "Gradient boosting scores: [ 0.26652348  0.21790389  0.23468266  0.28361578  0.25646593]\n",
      "CPU times: user 367 µs, sys: 48 µs, total: 415 µs\n",
      "Wall time: 400 µs\n",
      "Stochastic gradient descent scores: [ 0.13782795  0.17477684  0.17955375  0.16834757  0.23984268]\n",
      "CPU times: user 2.21 ms, sys: 203 µs, total: 2.42 ms\n",
      "Wall time: 636 µs\n",
      "Random forest scores: [ 0.26874577  0.18110542  0.18501762  0.19344226  0.24045222]\n",
      "CPU times: user 368 µs, sys: 51 µs, total: 419 µs\n",
      "Wall time: 404 µs\n",
      "Support vector scores: [ 0.19170348  0.25420771  0.21172118  0.24394988  0.24288247]\n",
      "CPU times: user 373 µs, sys: 47 µs, total: 420 µs\n",
      "Wall time: 409 µs\n",
      "K-Nearest neighbors scores: [ 0.12390461  0.21607539  0.16480607  0.19959109  0.15646635]\n",
      "CPU times: user 376 µs, sys: 42 µs, total: 418 µs\n",
      "Wall time: 411 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq1_train, Y_4_train, 'Y4', 'q', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.22452283  0.23788297  0.21214018  0.27655495  0.2738415 ]\n",
      "CPU times: user 1.94 ms, sys: 198 µs, total: 2.14 ms\n",
      "Wall time: 541 µs\n",
      "Gradient boosting scores: [ 0.30758168  0.26713498  0.28044592  0.29316499  0.28584792]\n",
      "CPU times: user 437 µs, sys: 96 µs, total: 533 µs\n",
      "Wall time: 513 µs\n",
      "Stochastic gradient descent scores: [ 0.09754587  0.21773917  0.19326022  0.21169039  0.11202905]\n",
      "CPU times: user 1.51 ms, sys: 109 µs, total: 1.62 ms\n",
      "Wall time: 419 µs\n",
      "Random forest scores: [ 0.25018653  0.19682672  0.21578956  0.19285591  0.23624485]\n",
      "CPU times: user 417 µs, sys: 55 µs, total: 472 µs\n",
      "Wall time: 459 µs\n",
      "Support vector scores: [ 0.1876356   0.24472353  0.22042767  0.26994928  0.23997731]\n",
      "CPU times: user 416 µs, sys: 48 µs, total: 464 µs\n",
      "Wall time: 449 µs\n",
      "K-Nearest neighbors scores: [ 0.14464612  0.23508972  0.19954673  0.25354423  0.16324948]\n",
      "CPU times: user 359 µs, sys: 31 µs, total: 390 µs\n",
      "Wall time: 395 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq2_train, Y_4_train, 'Y4', 'q', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_2_train = combine_targets(Y_4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.43167188  0.43716142  0.33032901  0.38145576  0.44886286]\n",
      "CPU times: user 455 µs, sys: 53 µs, total: 508 µs\n",
      "Wall time: 514 µs\n",
      "Gradient boosting scores: [ 0.39295262  0.41963703  0.35488716  0.40513891  0.42075466]\n",
      "CPU times: user 423 µs, sys: 47 µs, total: 470 µs\n",
      "Wall time: 456 µs\n",
      "Stochastic gradient descent scores: [ 0.32241528  0.27156272  0.24350259  0.24062507  0.40652804]\n",
      "CPU times: user 396 µs, sys: 42 µs, total: 438 µs\n",
      "Wall time: 431 µs\n",
      "Random forest scores: [ 0.378223    0.32143512  0.28146764  0.28709467  0.3065817 ]\n",
      "CPU times: user 378 µs, sys: 51 µs, total: 429 µs\n",
      "Wall time: 416 µs\n",
      "Support vector scores: [ 0.3775485   0.48733972  0.38074459  0.39140343  0.47187592]\n",
      "CPU times: user 384 µs, sys: 62 µs, total: 446 µs\n",
      "Wall time: 418 µs\n",
      "K-Nearest neighbors scores: [ 0.37936868  0.38583587  0.28353895  0.30880422  0.37139128]\n",
      "CPU times: user 497 µs, sys: 81 µs, total: 578 µs\n",
      "Wall time: 548 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr1_train, Y_2_train, 'Y2', 'r', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.42618452  0.42513564  0.35899455  0.38593217  0.4251092 ]\n",
      "CPU times: user 449 µs, sys: 62 µs, total: 511 µs\n",
      "Wall time: 489 µs\n",
      "Gradient boosting scores: [ 0.38513774  0.43915503  0.37605331  0.37161997  0.46805529]\n",
      "CPU times: user 406 µs, sys: 49 µs, total: 455 µs\n",
      "Wall time: 440 µs\n",
      "Stochastic gradient descent scores: [ 0.17020878  0.34782961  0.18299162  0.31086803  0.18311287]\n",
      "CPU times: user 621 µs, sys: 79 µs, total: 700 µs\n",
      "Wall time: 686 µs\n",
      "Random forest scores: [ 0.35090501  0.32949443  0.27699072  0.30588534  0.35931672]\n",
      "CPU times: user 390 µs, sys: 268 µs, total: 658 µs\n",
      "Wall time: 647 µs\n",
      "Support vector scores: [ 0.43023769  0.48165018  0.40594639  0.44691304  0.43776314]\n",
      "CPU times: user 407 µs, sys: 52 µs, total: 459 µs\n",
      "Wall time: 444 µs\n",
      "K-Nearest neighbors scores: [ 0.31719041  0.42944875  0.32856167  0.4399548   0.33596374]\n",
      "CPU times: user 412 µs, sys: 46 µs, total: 458 µs\n",
      "Wall time: 464 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xr2_train, Y_2_train, 'Y2', 'r', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.2972942   0.37115397  0.25967329  0.3340202   0.38267578]\n",
      "CPU times: user 366 µs, sys: 45 µs, total: 411 µs\n",
      "Wall time: 399 µs\n",
      "Gradient boosting scores: [ 0.35939606  0.42842498  0.36121478  0.4114983   0.43059699]\n",
      "CPU times: user 541 µs, sys: 56 µs, total: 597 µs\n",
      "Wall time: 604 µs\n",
      "Stochastic gradient descent scores: [ 0.29544566  0.23611596  0.25351706  0.24278026  0.30709921]\n",
      "CPU times: user 385 µs, sys: 35 µs, total: 420 µs\n",
      "Wall time: 425 µs\n",
      "Random forest scores: [ 0.26891534  0.33446239  0.26380669  0.39279255  0.31475217]\n",
      "CPU times: user 378 µs, sys: 47 µs, total: 425 µs\n",
      "Wall time: 417 µs\n",
      "Support vector scores: [ 0.29994768  0.39759252  0.30692306  0.32998724  0.39304805]\n",
      "CPU times: user 373 µs, sys: 49 µs, total: 422 µs\n",
      "Wall time: 411 µs\n",
      "K-Nearest neighbors scores: [ 0.28055197  0.33031239  0.27146334  0.31050098  0.27863159]\n",
      "CPU times: user 424 µs, sys: 47 µs, total: 471 µs\n",
      "Wall time: 459 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq1_train, Y_2_train, 'Y2', 'q', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression scores: [ 0.29759495  0.37115397  0.27212242  0.34503506  0.33551655]\n",
      "CPU times: user 679 µs, sys: 156 µs, total: 835 µs\n",
      "Wall time: 740 µs\n",
      "Gradient boosting scores: [ 0.36814063  0.43652168  0.34853982  0.39961019  0.49349375]\n",
      "CPU times: user 370 µs, sys: 45 µs, total: 415 µs\n",
      "Wall time: 413 µs\n",
      "Stochastic gradient descent scores: [ 0.29018522  0.26024534  0.21956142  0.18770827  0.24568734]\n",
      "CPU times: user 364 µs, sys: 31 µs, total: 395 µs\n",
      "Wall time: 401 µs\n",
      "Random forest scores: [ 0.3884235   0.33545666  0.33829455  0.34709783  0.37455584]\n",
      "CPU times: user 428 µs, sys: 56 µs, total: 484 µs\n",
      "Wall time: 462 µs\n",
      "Support vector scores: [ 0.30022185  0.37377346  0.2691068   0.367602    0.3692935 ]\n",
      "CPU times: user 486 µs, sys: 53 µs, total: 539 µs\n",
      "Wall time: 543 µs\n",
      "K-Nearest neighbors scores: [ 0.3019092   0.35563773  0.28177393  0.36219638  0.21007284]\n",
      "CPU times: user 457 µs, sys: 43 µs, total: 500 µs\n",
      "Wall time: 505 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials(Xq2_train, Y_2_train, 'Y2', 'q', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lrc</th>\n",
       "      <th>gbc</th>\n",
       "      <th>sgd</th>\n",
       "      <th>rfc</th>\n",
       "      <th>svc</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Y16</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">r</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0586287</td>\n",
       "      <td>0.0679115</td>\n",
       "      <td>0.0377768</td>\n",
       "      <td>0.0442958</td>\n",
       "      <td>0.0806177</td>\n",
       "      <td>0.0540436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0634823</td>\n",
       "      <td>0.0700779</td>\n",
       "      <td>0.0481633</td>\n",
       "      <td>0.0690347</td>\n",
       "      <td>0.0869886</td>\n",
       "      <td>0.0553248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">q</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0582151</td>\n",
       "      <td>0.0688561</td>\n",
       "      <td>0.0410762</td>\n",
       "      <td>0.0454181</td>\n",
       "      <td>0.0479186</td>\n",
       "      <td>0.0322822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0605747</td>\n",
       "      <td>0.0601833</td>\n",
       "      <td>0.040152</td>\n",
       "      <td>0.0568523</td>\n",
       "      <td>0.0529799</td>\n",
       "      <td>0.0404891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Y8</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">r</th>\n",
       "      <th>1</th>\n",
       "      <td>0.132942</td>\n",
       "      <td>0.127362</td>\n",
       "      <td>0.0642785</td>\n",
       "      <td>0.120029</td>\n",
       "      <td>0.152139</td>\n",
       "      <td>0.111231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.126975</td>\n",
       "      <td>0.144819</td>\n",
       "      <td>0.0928825</td>\n",
       "      <td>0.115875</td>\n",
       "      <td>0.160894</td>\n",
       "      <td>0.11504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">q</th>\n",
       "      <th>1</th>\n",
       "      <td>0.12411</td>\n",
       "      <td>0.139355</td>\n",
       "      <td>0.0861045</td>\n",
       "      <td>0.10714</td>\n",
       "      <td>0.115175</td>\n",
       "      <td>0.0992959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133207</td>\n",
       "      <td>0.132308</td>\n",
       "      <td>0.0842564</td>\n",
       "      <td>0.11973</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.112558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Y4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">r</th>\n",
       "      <th>1</th>\n",
       "      <td>0.254981</td>\n",
       "      <td>0.260609</td>\n",
       "      <td>0.135703</td>\n",
       "      <td>0.20078</td>\n",
       "      <td>0.277151</td>\n",
       "      <td>0.207983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241278</td>\n",
       "      <td>0.281035</td>\n",
       "      <td>0.147871</td>\n",
       "      <td>0.210885</td>\n",
       "      <td>0.293853</td>\n",
       "      <td>0.233377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">q</th>\n",
       "      <th>1</th>\n",
       "      <td>0.236484</td>\n",
       "      <td>0.251838</td>\n",
       "      <td>0.18007</td>\n",
       "      <td>0.213753</td>\n",
       "      <td>0.228893</td>\n",
       "      <td>0.172169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.244988</td>\n",
       "      <td>0.286835</td>\n",
       "      <td>0.166453</td>\n",
       "      <td>0.218381</td>\n",
       "      <td>0.232543</td>\n",
       "      <td>0.199215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Y2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">r</th>\n",
       "      <th>1</th>\n",
       "      <td>0.405896</td>\n",
       "      <td>0.398674</td>\n",
       "      <td>0.296927</td>\n",
       "      <td>0.31496</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>0.345788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404271</td>\n",
       "      <td>0.408004</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.324518</td>\n",
       "      <td>0.440502</td>\n",
       "      <td>0.370224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">q</th>\n",
       "      <th>1</th>\n",
       "      <td>0.328963</td>\n",
       "      <td>0.398226</td>\n",
       "      <td>0.266992</td>\n",
       "      <td>0.314946</td>\n",
       "      <td>0.3455</td>\n",
       "      <td>0.294292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.324285</td>\n",
       "      <td>0.409261</td>\n",
       "      <td>0.240678</td>\n",
       "      <td>0.356766</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.302318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lrc        gbc        sgd        rfc        svc        knn\n",
       "Y16 r 1  0.0586287  0.0679115  0.0377768  0.0442958  0.0806177  0.0540436\n",
       "      2  0.0634823  0.0700779  0.0481633  0.0690347  0.0869886  0.0553248\n",
       "    q 1  0.0582151  0.0688561  0.0410762  0.0454181  0.0479186  0.0322822\n",
       "      2  0.0605747  0.0601833   0.040152  0.0568523  0.0529799  0.0404891\n",
       "Y8  r 1   0.132942   0.127362  0.0642785   0.120029   0.152139   0.111231\n",
       "      2   0.126975   0.144819  0.0928825   0.115875   0.160894    0.11504\n",
       "    q 1    0.12411   0.139355  0.0861045    0.10714   0.115175  0.0992959\n",
       "      2   0.133207   0.132308  0.0842564    0.11973   0.112506   0.112558\n",
       "Y4  r 1   0.254981   0.260609   0.135703    0.20078   0.277151   0.207983\n",
       "      2   0.241278   0.281035   0.147871   0.210885   0.293853   0.233377\n",
       "    q 1   0.236484   0.251838    0.18007   0.213753   0.228893   0.172169\n",
       "      2   0.244988   0.286835   0.166453   0.218381   0.232543   0.199215\n",
       "Y2  r 1   0.405896   0.398674   0.296927    0.31496   0.421782   0.345788\n",
       "      2   0.404271   0.408004   0.239002   0.324518   0.440502   0.370224\n",
       "    q 1   0.328963   0.398226   0.266992   0.314946     0.3455   0.294292\n",
       "      2   0.324285   0.409261   0.240678   0.356766      0.336   0.302318"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data cannot perform better than reasonably well on binary classification, where robust scaling clearly outperforms quantile transformation on the three highest-scoring algorithms — support vector, logistic regression amd gradient boosting. The second feature set performs better, but would performance improve by dropping the most extreme outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xx = list(set(xx_outliers) & set(list(data_train.index)))\n",
    "test_xx = list(set(xx_outliers) & set(list(data_test.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xr1_noxx_train = Xr1_train.drop(train_xx)\n",
    "Xr2_noxx_train = Xr2_train.drop(train_xx)\n",
    "Y_2_noxx_train = Y_2_train.drop(train_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2 = pd.MultiIndex.from_product([['full', 'no_xx'], [1, 2]])\n",
    "results2 = pd.DataFrame(index=index2, columns=names)\n",
    "\n",
    "results2.loc['full', 1] = results.loc['Y2', 'r', 1]\n",
    "results2.loc['full', 2] = results.loc['Y2', 'r', 2]\n",
    "\n",
    "\n",
    "def run_trials2(X, Y, selected, feature_set):\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        score = np.mean(cross_val_score(clf, X, Y, cv=5, scoring=matthews))\n",
    "        results2.loc[selected, feature_set][name] = score\n",
    "        %time print('{} average score: {}'.format(full_names[name], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average score: 0.4056613832042782\n",
      "CPU times: user 70 µs, sys: 47 µs, total: 117 µs\n",
      "Wall time: 105 µs\n",
      "Gradient boosting average score: 0.4042536807096672\n",
      "CPU times: user 77 µs, sys: 47 µs, total: 124 µs\n",
      "Wall time: 107 µs\n",
      "Stochastic gradient descent average score: 0.28466801367642225\n",
      "CPU times: user 56 µs, sys: 28 µs, total: 84 µs\n",
      "Wall time: 88 µs\n",
      "Random forest average score: 0.29164647598965676\n",
      "CPU times: user 68 µs, sys: 47 µs, total: 115 µs\n",
      "Wall time: 104 µs\n",
      "Support vector average score: 0.4382835309464636\n",
      "CPU times: user 79 µs, sys: 48 µs, total: 127 µs\n",
      "Wall time: 108 µs\n",
      "K-Nearest neighbors average score: 0.3602592184275963\n",
      "CPU times: user 59 µs, sys: 32 µs, total: 91 µs\n",
      "Wall time: 96.1 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials2(Xr1_noxx_train, Y_2_noxx_train, 'no_xx', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average score: 0.41151109255300933\n",
      "CPU times: user 108 µs, sys: 121 µs, total: 229 µs\n",
      "Wall time: 197 µs\n",
      "Gradient boosting average score: 0.3968723565322684\n",
      "CPU times: user 152 µs, sys: 90 µs, total: 242 µs\n",
      "Wall time: 214 µs\n",
      "Stochastic gradient descent average score: 0.31406481700184186\n",
      "CPU times: user 55 µs, sys: 28 µs, total: 83 µs\n",
      "Wall time: 87 µs\n",
      "Random forest average score: 0.35162322026120235\n",
      "CPU times: user 78 µs, sys: 54 µs, total: 132 µs\n",
      "Wall time: 119 µs\n",
      "Support vector average score: 0.43289122441388467\n",
      "CPU times: user 64 µs, sys: 43 µs, total: 107 µs\n",
      "Wall time: 102 µs\n",
      "K-Nearest neighbors average score: 0.35843025979023346\n",
      "CPU times: user 65 µs, sys: 42 µs, total: 107 µs\n",
      "Wall time: 101 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials2(Xr2_noxx_train, Y_2_noxx_train, 'no_xx', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lrc</th>\n",
       "      <th>gbc</th>\n",
       "      <th>sgd</th>\n",
       "      <th>rfc</th>\n",
       "      <th>svc</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full</th>\n",
       "      <th>1</th>\n",
       "      <td>0.405896</td>\n",
       "      <td>0.398674</td>\n",
       "      <td>0.296927</td>\n",
       "      <td>0.31496</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>0.345788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.404271</td>\n",
       "      <td>0.408004</td>\n",
       "      <td>0.239002</td>\n",
       "      <td>0.324518</td>\n",
       "      <td>0.440502</td>\n",
       "      <td>0.370224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">no_xx</th>\n",
       "      <th>1</th>\n",
       "      <td>0.405661</td>\n",
       "      <td>0.404254</td>\n",
       "      <td>0.284668</td>\n",
       "      <td>0.291646</td>\n",
       "      <td>0.438284</td>\n",
       "      <td>0.360259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.411511</td>\n",
       "      <td>0.396872</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.351623</td>\n",
       "      <td>0.432891</td>\n",
       "      <td>0.35843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lrc       gbc       sgd       rfc       svc       knn\n",
       "full  1  0.405896  0.398674  0.296927   0.31496  0.421782  0.345788\n",
       "      2  0.404271  0.408004  0.239002  0.324518  0.440502  0.370224\n",
       "no_xx 1  0.405661  0.404254  0.284668  0.291646  0.438284  0.360259\n",
       "      2  0.411511  0.396872  0.314065  0.351623  0.432891   0.35843"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choices between the full dataset or the dataset without the most extreme outliers, and between the feaure sets is not clear. See how the top three models perform on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_test = pd.DataFrame(robust.fit_transform(data_test.drop(['urban_inf'], axis=1)),\n",
    "                       index=data_test.index, columns=data_test.drop(['urban_inf'], axis=1).columns)\n",
    "r_test['urban_inf'] = data_test['urban_inf']\n",
    "\n",
    "Xr1_test = r_test.loc[:, r_features]\n",
    "Xr1_test = pd.get_dummies(Xr1_test, prefix='urb_inf_', columns=['urban_inf'])\n",
    "\n",
    "Xr2_test = r_test.loc[:, features2]\n",
    "Xr2_test = pd.get_dummies(Xr2_test, prefix='urb_inf_', columns=['urban_inf'])\n",
    "\n",
    "Xr1_noxx_test = r_test.loc[:, r_features].drop(test_xx)\n",
    "Xr1_noxx_test = pd.get_dummies(Xr1_noxx_test, prefix='urb_inf_', columns=['urban_inf'])\n",
    "\n",
    "Xr2_noxx_test = r_test.loc[:, features2].drop(test_xx)\n",
    "Xr2_noxx_test = pd.get_dummies(Xr2_noxx_test, prefix='urb_inf_', columns=['urban_inf'])\n",
    "\n",
    "Y_16_test = targets_test.apply(lambda x: '0-1.9' if x == '<2' else x)\n",
    "Y_16_test = Y_16_test.apply(lambda x: '30-31.9' if x == '30+' else x)\n",
    "Y_8_test = combine_targets(Y_16_test)\n",
    "Y_4_test = combine_targets(Y_8_test)\n",
    "Y_2_test = combine_targets(Y_4_test)\n",
    "\n",
    "Y_2_noxx_test = Y_2_test.drop(test_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index3 = pd.MultiIndex.from_product([['full', 'no_xx'], [1, 2]])\n",
    "names3 = ['lrc', 'gbc', 'svc']\n",
    "classifiers3 = [classifiers[i] for i in [0, 1, 4]]\n",
    "results3 = pd.DataFrame(index=index3, columns=names3)\n",
    "\n",
    "def run_trials3(X_train, X_test, Y_train, Y_test, selected, feature_set):\n",
    "    for name, clf in zip(names3, classifiers3):\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_pred = clf.predict(X_test)\n",
    "        score = matthews_corrcoef(Y_test, Y_pred)\n",
    "        results3.loc[selected, feature_set][name] = score\n",
    "        %time print('{} average score: {}'.format(full_names[name], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average score: 0.3599204025324622\n",
      "CPU times: user 803 µs, sys: 113 µs, total: 916 µs\n",
      "Wall time: 220 µs\n",
      "Gradient boosting average score: 0.39099022521044685\n",
      "CPU times: user 74 µs, sys: 46 µs, total: 120 µs\n",
      "Wall time: 106 µs\n",
      "Support vector average score: 0.36786152851482773\n",
      "CPU times: user 74 µs, sys: 48 µs, total: 122 µs\n",
      "Wall time: 108 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials3(Xr1_train, Xr1_test, Y_2_train, Y_2_test, 'full', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average score: 0.3722667110752942\n",
      "CPU times: user 699 µs, sys: 251 µs, total: 950 µs\n",
      "Wall time: 323 µs\n",
      "Gradient boosting average score: 0.39434950071387503\n",
      "CPU times: user 70 µs, sys: 51 µs, total: 121 µs\n",
      "Wall time: 107 µs\n",
      "Support vector average score: 0.38445348724604494\n",
      "CPU times: user 68 µs, sys: 45 µs, total: 113 µs\n",
      "Wall time: 97 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials3(Xr2_train, Xr2_test, Y_2_train, Y_2_test, 'full', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average score: 0.3799486774825333\n",
      "CPU times: user 913 µs, sys: 176 µs, total: 1.09 ms\n",
      "Wall time: 273 µs\n",
      "Gradient boosting average score: 0.39480838688883063\n",
      "CPU times: user 72 µs, sys: 50 µs, total: 122 µs\n",
      "Wall time: 109 µs\n",
      "Support vector average score: 0.3846390616316681\n",
      "CPU times: user 125 µs, sys: 89 µs, total: 214 µs\n",
      "Wall time: 185 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials3(Xr1_noxx_train, Xr1_noxx_test, Y_2_noxx_train, Y_2_noxx_test, 'no_xx', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression average score: 0.3853984655080666\n",
      "CPU times: user 842 µs, sys: 124 µs, total: 966 µs\n",
      "Wall time: 236 µs\n",
      "Gradient boosting average score: 0.42078681573621357\n",
      "CPU times: user 83 µs, sys: 50 µs, total: 133 µs\n",
      "Wall time: 112 µs\n",
      "Support vector average score: 0.390006747579955\n",
      "CPU times: user 105 µs, sys: 92 µs, total: 197 µs\n",
      "Wall time: 154 µs\n"
     ]
    }
   ],
   "source": [
    "run_trials3(Xr2_noxx_train, Xr2_noxx_test, Y_2_noxx_train, Y_2_noxx_test, 'no_xx', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lrc</th>\n",
       "      <th>gbc</th>\n",
       "      <th>svc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full</th>\n",
       "      <th>1</th>\n",
       "      <td>0.35992</td>\n",
       "      <td>0.39099</td>\n",
       "      <td>0.367862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372267</td>\n",
       "      <td>0.39435</td>\n",
       "      <td>0.384453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">no_xx</th>\n",
       "      <th>1</th>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.394808</td>\n",
       "      <td>0.384639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385398</td>\n",
       "      <td>0.420787</td>\n",
       "      <td>0.390007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lrc       gbc       svc\n",
       "full  1   0.35992   0.39099  0.367862\n",
       "      2  0.372267   0.39435  0.384453\n",
       "no_xx 1  0.379949  0.394808  0.384639\n",
       "      2  0.385398  0.420787  0.390007"
      ]
     },
     "execution_count": 975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature set with the most extreme outliers removed performed better with all the classifiers, as did the second feature set. Both will be optimized, since the support vector scores are not much higher and logistic regression results are more interpretable. The second feature also consistently outperfoms the first with both of these classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_bi_train = data.loc[list(Y_2_noxx_train.index), 'numeric'].apply(lambda x: 0 if x < 15 else 1)\n",
    "Y_bi_test = data.loc[list(Y_2_noxx_test.index), 'numeric'].apply(lambda x: 0 if x < 15 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(clf, params, X_train, X_test, Y_train, Y_test):\n",
    "    model = GridSearchCV(clf, param_grid=params, scoring=matthews)\n",
    "    model.fit(X_train, Y_train)\n",
    "    print('Optimal parameters: {}'.format(model.best_params_))\n",
    "    preds = model.predict(X_test)\n",
    "    print('Matthews score: {}'.format(matthews_corrcoef(Y_test, preds)))\n",
    "    print('ROC-AUC score: {}'.format(roc_auc_score(Y_test, preds)))\n",
    "    print(confusion_matrix(Y_test, preds))\n",
    "    residuals = pd.DataFrame(model.best_estimator_.decision_function(X_test))\n",
    "    plt.scatter(residuals.index, residuals)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc_params = { 'loss': ['deviance', 'exponential'], 'learning_rate': [.01, .05, .1, .15],\n",
    "                'n_estimators': [50, 100, 150], 'max_depth': [3, 4],\n",
    "                'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2]}\n",
    "\n",
    "svc_params = {'C': [0.5, 1, 4, 7], 'kernel': ['linear', 'poly', 'rbf'],\n",
    "             'gamma': [0.1, 0.12, 0.14], 'tol': [1e-7, 5e-7, 1e-6, 5e-6]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Matthews score: 0.44679152383970955\n",
      "ROC-AUC score: 0.7224836284259034\n",
      "[[237  73]\n",
      " [ 85 181]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAD8CAYAAABTolwLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngxFbfzraAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cf8bbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbc_1 = optimize(gbc, gbc_params, Xr2_noxx_train, Xr2_noxx_test, Y_bi_train, Y_bi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'C': 1, 'gamma': 0.14, 'kernel': 'rbf', 'tol': 1e-07}\n",
      "Matthews score: 0.45729204350294067\n",
      "ROC-AUC score: 0.7291777831675964\n",
      "[[226  84]\n",
      " [ 72 194]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAD8CAYAAABTolwLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDWQFPUoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ecab2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc_1 = optimize(svc, svc_params, Xr2_noxx_train, Xr2_noxx_test, Y_bi_train, Y_bi_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
